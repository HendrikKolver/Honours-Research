\documentclass[12pt]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[T1]{fontenc}
\usepackage[margin=1.0in]{geometry}
\usepackage{mathtools}
\usepackage{setspace}
\setstretch{1.0}

\usepackage{graphicx}
\graphicspath{ {images/}}

\title{Self recovering capabilities in images using the BPCS Steganography algorithm}

\author{Hendrik J Kolver}

\date{\today}

\begin{document}
\maketitle

\begin{abstract}

\noindent Abstract of this paper and what I wrote in it.
This will give the reader a short overview of what they can expect to find in this paper.

\end{abstract}

\tableofcontents
\section{Introduction}

\subsection{Introduction}
This paper proposes a novel method for self-recovering images.

\hspace{0pt} \\
Self-recovering images: Self-recovering images are images that have their own image content embedded into themselves using image steganography techniques. 
This content can then be extracted from the image at a later stage in order to reconstruct the image to an approximate original state in the case that the image was damaged.

\hspace{0pt} \\
Current self-recovering image techniques generally have poor quality restoration capabilities, damage the original image greatly or does not allow a large amount of the original image to be damaged before recovery is no longer possible.
The proposed method will focus on improving the quality of self-recovering images.

\subsection{Problem statement}
The proposed method attempts to achieve the following
\begin{itemize}
	\item The proposed method should achieve a high quality image after the self-embedding process as well as after the restoration process with a reasonable tamper rate(compared to currently available methods)
	\item There should not be clear visual evidence that the image has been modified after embedding as well as after restoration and the image should still carry it's original semantic meaning
\end{itemize}

\subsection{Research methodology}
Firstly a literature review was conducted to determine the currently available methods for self-recovering images. 
After a shortcoming was identified the proposed method was designed and then implemented in the form of a Java software application in order to attempt to improve on the identified shortcoming. 
The results of the proposed method were then compared to the results of other relevant self-recovering image methods.

\subsection{Terminology}
This paper makes use of several terms and acronyms.
This section serves to make the meaning of those terms clear.

\begin{itemize}
  \item Original Image: This refers to the original image without any modifications.
  \item Embedding: Embedding in the context of this paper refers to the process of storing digital information in an image's content in such a way that the original image is still distinguishable.
  \item Image after embedding: This refers to the the original image after the embedding process has been applied.
  \item Image after reconstruction: This refers to the reconstructed version of the original image that was obtained by applying the reconstruction process to the image after embedding.
  \item LSB: This refers to the least significant bit in a binary string.
  \item MSB: This refers to the most significant bit/bits in a binary string.
  \item Section, Image section, Pixel section: This refers to a section of 8x8 pixels in an image.
  \item Bit plane: A bit plane is a 8x8 grid representation of a specific bit value's for a specific pixel section. Each pixel has 24 bits which in total represents each colour, 8 bits per colour. these bits are the 8 binary bits that represent the numerical value of the colour. These 8 bits are separated from each other and are each stored in a 8x8 grid in the same location as that of the pixel in the pixel section. This process is repeated for each pixel in the pixel section and the result is 8, 8x8 grids of binary numbers. Each one of these 8 grids represent a single bit plane. 
  \item Block: This refers to an individual bit plane of a specific section of the image. There are 8 such blocks in each section since each pixel is represented by 8 bits for each colour.
  \item BPCS Steganography: Bit-Plane Complexity Segmentation Steganography
\end{itemize}

\subsection{Conclusion}
This chapter discussed the purpose behind self-recovering images as well as the aim of this research and the proposed method. 
The research methodology followed was described. A list of terminologies used in this paper was also given.
The next chapter will give a more detailed overview of all the components that make up self-recovering images. 

\section{Self-recovering images}

\subsection{Introduction}
Self-recovering images are images that have their own image content embedded into themselves using image steganography techniques. 
This content can then be extracted from the image at a later stage in order to reconstruct the image to an approximate original state in the case that the image was damaged.

\hspace{0pt} \\
In order to understand the self-recovering system proposed in this dissertation, one has to understand the underlying technologies.  This chapter will look at image steganography in more detail in section \ref{introSteganography} and at watermarking in section \ref{introFragWatermarking}. Self-embedding and recovery will be discussed in section \ref{introSelfEmbedRecovery} with a conclusion in section \ref{introConclusion}

Self recovering images poses an interesting problem.
\hspace{0pt} \\
//TODO <add formal definition here>
\hspace{0pt} \\
There is an inherent trade-off between the quality of the image after embedding and the quality of the image after recovery.

\subsection{Steganography}
\label{introSteganography}
Steganography is the process of hiding information in such a way that it does not get detected \cite{johnson1998exploring}.
Steganography, derived from Greek means "covered writing".
This means it differs from cryptography which does not attempt to hide information but merely scrambles it so it cannot be understood.
Steganography does not scramble the information but rather relies on the information to remain hidden.

\hspace{0pt} \\
The proposed method uses steganography to embed the information into the image in a way that is not easily visibly detectable by a human observer.
A successful stegnographic method has certain characteristics:
\begin{itemize}
	\item Invisibility: How easy it is to detect that information has been embedded using steganography.
	\item Robustness: How much of the image that is embedded into can be modified without compromising the embedded information.
	\item Capacity: The maximal number of bits that can be embedded without introducing statistically detectable artifacts \cite{fridrich2009steganography}. It should also be added that the embedding must also not be visually detectable.
\end{itemize}
Least significant bit embedding (LSB) is a stegnographic method that can be used to embed information. 
LSB works by replacing the least significant bit (or n least significant bits) of an image colour value with the binary bits from a message. The least significant bit of a colour value is the binary bit/s that carry the least value.

\hspace{0pt} \\
BPCS Steganography is another stegnographic embedding method \cite{beaullieubpcs}.

\hspace{0pt} \\
This method works with the following steps:
\begin{enumerate}
  \item Get the binary representation of the image
  \item Convert the binary representation into Gray code
  \item Divide the image into bit planes
  \item Divide the bit planes into 8x8 pixel blocks
  \item Calculate the complexity for each block
  \item Divide the image reference content to be embedded into similar binary 8x8 blocks
  \item Calculate the complexity for each image reference block and conjugate if not complex enough
  \item for each image block that is complex enough, replace that block with the next image reference content block
  \item Convert the blocks back to binary representation
  \item reconstruct the image from the processed blocks 
\end{enumerate}

\hspace{0pt} \\
The BPCS algorithm is a high capacity embedding algorithm. The goal of the BPCS algorithm is thus to embed as much data as possible into a cover image without detection \cite{beaullieubpcs}.
This refers to detection by human perception as well as statistical analysis although the latter is not the focus of this paper.
The BPCS algorithm uses an adaptive scheme to classify blocks that are suitable for embedding (similar to \ref{DynamicBlockOverview}).
BPCS steg differs however in the fact that the blocks can be conjugated in a checker board pattern to increase complexity and decrease detectability if needs be.
BPCS steg also differs in the way in which embedding takes place.
Instead of always embedding into the 3-LSB planes as in \ref{DynamicBlockOverview}.
Bit planes are dynamically allocated for embedding.
One section may thus only embed into one bit plane while another may use all 7 available bit planes.

\subsection{Fragile Watermarking}
//TODO <add formal definition here> 
\label{introFragWatermarking}
Fragile watermarking is a variation of traditional watermarking where a watermark is embedded into an image such that subsequent alterations to the watermarked image can be detected with high probability \cite{lin1999review}.
This means that if modifications are made to the watermarked image it would be possible to detect that modifications were made as well as what parts of the image were modified.
This is a necessary component in self recovering images because in order to be able to recover image data it first needs to be determined if the image after embedding has been modified and if so what parts of the image was modified.

\iffalse 
	//TODO this already covered in section \ref{impFragileWatermark}
	The proposed method will use this information to determine which parts of the image should be recovered from the image reference content.
	A fragile watermark is used for this purpose. 
\fi

\subsection{Self embedding and recovery}
\label{introSelfEmbedRecovery}
Self embedding is a scheme where image content is embedded into the image itself. This embedded content can then later be used to recover damaged or modified parts of the image without accessing the original image itself \cite{fridrich1999images}.
A self embedding and recovery scheme (Further referred to as reconstruction) such as the proposed method contains a couple of high level steps.
Firstly the authentic image content is embedded into the original image along with a fragile watermark.
The resulting image is referred to as the image after embedding
This watermark will help determine later on which parts of the image after embedding was modified if any (see \ref{introFragWatermarking}).
When the authentic image needs to be reconstructed, after modification, the fragile watermark is used to determine which content was modified.
An attempt is then made to extract the original content for the areas that were modified in the image after embedding.
If this process is successful the user is left with a high quality reconstruction of the original image.

\hspace{0pt} \\
There is an inherent quality trade-off present within self embedding schemes.
The trade-off exists between the image after embedding and the image after reconstruction.
If an embedding algorith such as LSB(Least significan bit) embedding is used the actual bit values of the original image are overwritten.
Naturally the more bit values are overwritten the more noise is introduced into the image.
This effectively reduces the quality of the image after embedding.

\hspace{0pt} \\
The solution to this would be to simply embed a small amount of information into the image to keep the noise low.
However this presents another problem.
The quality of the image after reconstruction is dependent on the amount of authentic image data (further referred to as the image reference content) embedded into the image.

\hspace{0pt} \\
To achieve maximum quality after embedding the embedded information must be as little as possible.
To achieve maximum quality after reconstruction the embedded image reference content must be as large as possible to be as close as possible to the original image.
There exists then a trade-off between the two.

\hspace{0pt} \\
It might be possible to increase the quality of the image after reconstruction while still keeping the quality after embedding high.
By using a high capacity embedding algorithm the overall embedding capacity is increased and a higher quality restoration image can be embedded. 

\hspace{0pt} \\
The proposed method in this paper attempts to apply the algorithm for BPCS Steganography
to the problem of self recovering images, specifically to increase overall quality.
The BPCS algorithm can achieve a very high capacity while still remaining undetectable through human perception.
This makes the BPCS algorithm a good choice to increase the capacity of a self recovering image scheme and possibly increase the quality through this process.

\subsection{Conclusion}
\label{introConclusion}
This chapter gave important background information regarding staganography in general as well as two stegnographic embedding methods, LSB embedding and BPCS steganography in section \ref{introSteganography}.
Fragile watermarking was discussed in section \ref{introFragWatermarking} as well as self embedding and recovery in section \ref{introSelfEmbedRecovery}.
The next chapter will discuss related work in existing self embedding techniques.

\section{Current self recovering image schemes and algorithms}

\subsection{Introduction}
//TODO

This section compares current content reconstruction algorithms using self embedding.
This serves to give an overview of what is currently available and to possibly highlight shortcomings of the current algorithms.
This would be useful to determine if the proposed method does indeed improve on existing methods. 
It would also help highlight strengths and shortcomings in the proposed method.
The methods analysed were chosen because they all provide good quality images after embedding as well as good quality images after reconstructed.
They also each offer an unique approach or aspect to the self recovering image problem.

\hspace{0pt} \\
There are 3 methods tested. An erasure channel model utilizing the remaining authentic content in section \ref{ErasureChannelOverview}, a method using difference expansion in section \ref{differenceExpansionOverview} and a method using dynamic block allocation \ref{DynamicBlockOverview}. A comparison between these 3 methods are provided in section \ref{litStudyCamparison}

\subsection{Overview}
//TODO <All the terms that have not been defined yet in the paper that will be used in this section should be defined here>

\subsubsection{Erasure channel model utilizing the remaining authentic content}
\label{ErasureChannelOverview}
The method proposed in \cite {korus2013efficient} uses an erasure channel
//TODO <define erasure channel> 
as a model for the content reconstruction problem.
The method uses LSB embedding to embed the image reference content into the image itself and uses a global spreading technique to spread the image reference content across the image.
The method also proposes that by using the remaining authentic content in the image it is possible to have a high tamper rate while at the same time achieving good quality images before and after reconstruction.

\hspace{0pt} \\
The method proposed in \cite {korus2013efficient} achieves good quality images after embedding with a PSNR 
//TODO <define PSNR and why is it important, this is possibly explained in another section> 
\textgreater 35dB. 
The method also achieves an image after reconstruction quality of 35dB \textless PSNR \textgreater 40dB and 40dB \textless PSNR with tamper rates of 50\% and 33\% respectively.
The method does not let the quality of the image after reconstruction deteriorate much if the tampering rate is increased up to a value of 50\%.
They do however note that they can only achieve a minimal increase in reconstruction performance by decreasing the amount of information in the image reference content.
By using only 50\% of the available capacity the maximal 
//TODO <define tampering rate earlier>
 tampering rate increases form 50\% to 59\%.

\hspace{0pt} \\
This method \cite {korus2013efficient} is thus quite robust since 50\% of the image may be tampered with before reconstruction ability starts to deteriorate.
The security //TODO <define security> for this method is also very good since the quality of the cover image is not very susceptible to visual checks.
The authors did not do any statistical analysis on the image.
The embedding capacity of this method is also acceptable, but because the method uses some of the authentic image data to aid in the reconstruction process the quality of the image, before and after reconstruction, is still very good even without a very high embedding capacity.  

\subsubsection{Method using difference expansion}
\label{differenceExpansionOverview}
Another method \cite {tian2003high} uses difference expansion and generalized LSB embedding.
Difference expansion works by exploiting the high redundancy that are present in images 
//TODO <Reference this, basically this reference \cite {tian2003high}>.
With difference expansion the payload is embedded in the difference of pixel values. 
For a pair of pixel values (x,y) \cite {tian2002reversible}. 
It should however be noted that image quality reduces rapidly as the  
//TODO <define payload size>
payload size is increased when using difference expansion. 
The method uses difference expansion and to achieve a high embedding capacity while keeping distortion relatively low.
The method achieves a PSNR \textgreater 35dB after embedding.
The method achieves an 
//TODO <define embedding capacity>
embedding capacity of 1.78bpp when using up to the 4th LSB on a 512x512 8bit gray-scale version of the Lena image.

\hspace{0pt} \\
The method's \cite {tian2003high} quality regarding the image after reconstruction is acceptable at roughly 50\%. 
The difference expansion this method uses provides extra space for embedding.
The authors did thus not implement compression on the image data because of the extra space the difference expansion provides.
The embedding capacity of this method could thus be further improved by compressing the embedded data. 
This could possibly lead to better quality than what their experimental results achieved at the expense of complexity.
Difference expansion thus seems a good solution to increase the embedding capacity while still keeping the distortion low.

\hspace{0pt} \\ 
The authors do not mention the image tamper rate that this method \cite {tian2003high} achieves.

\subsubsection{Dynamic block allocation for self embedding}
\label{DynamicBlockOverview}
Qian et al \cite{qian2011image} proposes a method for fragile watermarking with good image restoration capabilities.
The proposed method differs from the other methods mentioned in \ref{ErasureChannelOverview} and \ref{differenceExpansionOverview} due to the fact that the method does not embed the information into all blocks uniformly.
The method classifies different blocks of the image according to the block smoothness.
The less smooth the block is the more information will be embedded into it.
The authors argue that the current methods that use a fixed embedding size for each block are inadequate since less information should be embedded into the very smooth blocks and more should be embedded into the rough blocks \cite{qian2011image}.

\hspace{0pt} \\
The advantage of using this dynamic scheme is that there is visual distortion to the image after embedding. 
This is because if the specific block is already very rough (very busy visually) the human eye does not notice small changes.
If however the specific block is very smooth (very uniform visually) the human eye is more likely to notice small changes.
The method thus creates less distortion in the image after embedding than fixed size methods while still retaining good image after reconstruction quality \cite{qian2011image}. 

\hspace{0pt} \\
The method proposed by Qian et al \cite{qian2011image} uses 3 LSB bit planes
\iffalse 
	//TODO possibly define bit planes here although it is already defined in the terminology
\fi 
to embed the needed information in.
The method achieves good results in experimentation with a image after embedding PSNR \textgreater 37dB as well as a image after reconstruction PSNR = 35dB.
The method also allows for a tamper rate \textless 35\%.
The authors do not analyze the security of the algorithm.

\subsection{Comparison}
\label{litStudyCamparison}
Each of the methods described in \ref{ErasureChannelOverview}, \ref{differenceExpansionOverview} and \ref{DynamicBlockOverview} provide good quality images after embedding as well as good quality images after reconstruction.
There are however important differences.
The method described in \ref{ErasureChannelOverview} offers a very good tamper rate of 50\% compared to the method described in \ref{DynamicBlockOverview} which has a tamper rate of 35\%.
This means that a larger part of the image after embedding can be tampered with while still being able to reconstruct the image.

\hspace{0pt} \\
The method described in \ref{differenceExpansionOverview} achieves an image after embedding with a PSNR \textgreater 35dB, the method described in \ref{ErasureChannelOverview} achieves similar results, however the method described in \ref{DynamicBlockOverview} achieves an image after embedding PSNR \textgreater 37dB.
This means that the method described in \ref{DynamicBlockOverview} would have less noise in the image after embedding and would thus have better overall quality of the image after embedding.

\hspace{0pt} \\
At almost equal tamper rates of around 33\%-35\% the method described in \ref{ErasureChannelOverview} achieves an image after reconstruction PSNR \textgreater 40dB whereas the method described in \ref{DynamicBlockOverview} only achieves an image after reconstruction PSNR = 35dB.
The method described in \ref{differenceExpansionOverview} only achieves an image after reconstruction quality of about 50\% the original image.
This means that the method described in \ref{ErasureChannelOverview} would generally produce better quality reconstructed images than the methods described in \ref{DynamicBlockOverview} and \ref{differenceExpansionOverview}.

\hspace{0pt} \\
This means that the method described in \ref{ErasureChannelOverview} provides the best tamper rate and the best reconstructed image quality, and the method described in \ref{DynamicBlockOverview} provides the best image after embedding quality.
The method described in \ref{differenceExpansionOverview} provides decent quality of the image after embedding as well as the image after reconstruction.

\hspace{0pt} \\
All three methods thus provide good results and would serve as a good benchmark for comparing the method proposed in this paper.

\subsection{Conclusion}
This chapter looked at currently available methods for self-recovering images.
An erasure channel model utilizing the remaining authentic content in section \ref{ErasureChannelOverview}, a method using difference expansion in section \ref{differenceExpansionOverview} and a method using dynamic block allocation \ref{DynamicBlockOverview}.
A comparison between these methods was also provided in section \ref{litStudyCamparison}.
The next chapter will discuss the implementation of the of the self-recovering image method proposed in this paper.  

\section{Implementation}
\label{Implementation}
\subsection{Introduction}
//TODO

\subsection{Embedding}
\label{embedding}

The proposed method works with colour images which means that for each pixel there is a red, green and blue value. This means that each block effectively stores 3 bits for each pixel.

\subsubsection{BPCS steganography} 
\label{bpcsSteg}

BPCS Steg has an inherent property that if any part of the image is modified the embedded message will be lost.
This would obviously be a problem for the proposed method since the image will definitely be modified.

\hspace{0pt} \\
As a solution to this problem each bit plane block used for embedding is treated as a separate embedding entity.
There is thus no overlap between two different blocks used for embedding.
The image reference content is first processed using the method explained later in this section.
Each block has 12 pixels (with a bit depth of 16 bits) of the image reference content embedded into it.
An embedding map containing the location of the first pixel to be embedded in the block is also created.
Since the individual image reference content pixels are embedded in order it is only necessary to know the location of the first pixel.
This embedding map is then embedded into the LSB (Least significant bit) layer of that specific 8x8 block of pixels 
This allows the extractor to be able to identify where all the extracted pixels belong in the image even if the image has been modified.
This serves to give random access to the embedded content which is an essential property of self embedding as defined by (Korus et al. \cite{korus2013efficient}).
This is essential in order for the reconstruction process to function properly.

\hspace{0pt} \\
Total space available for embedding per block = (8*8)*3 = 64*3 = 192
\hspace{0pt} \\
Total embedded bits = 12*16 = 192

\paragraph{Image resizing}
\label{ImageCompression}
The image reference content that is embedded into the original image cannot be embedded with perfect quality due to space restrictions caused by the embedding algorithm. 
The proposed method however does not utilize compression as it is beyond the scope of this paper.
The proposed method rather reduces the bit rate of the image from 24 bits to 16 which reduces the size of each pixel by 6 bits.
The image's size is also reduced according to the space available for embedding.
When extracting the image reference content again the assembled image reference content is scaled up to it's original size of 512x512 pixels before completing the reconstruction.
This is done to ensure that the pixels contained in the image reference content matches up (location wise) with the pixels in the original image.

\paragraph{Block Spread}
It is very important how the image reference content is spread across the image because this affects the tamper rate
\hspace{0pt} \\
\cite{korus2013efficient} Has found that it is important that the image reference content should be uniformly distributed across the image during embedding and that each part of the image after should contain equal information about the image reference content.
Due to the fact that the proposed method uses an adaptive embedding algorithm it is not possible for each part of the image after embedding to contain equal information about the image reference content.
The proposed method does however distribute the embedded image reference content evenly among the blocks that were identified as suitable for embedding.
The proposed method uses a simple method for spreading the image reference content across the image.
The image reference content to be embedded is first divided into blocks as per the BPCS steg algorithm.
These blocks are subsequently stored in a list. 
The created list is then reversed before embedding.
Reversing the list means that each corner of the image in the image reference content is embedded into the opposing corner diagonally in the original image. For example image reference content that contains the bottom right part of the original image will now be embedded into the top left part of the original image during embedding.

This creates an effect where the embedded image reference content is far away from the content that it is referencing.
This is important because if a piece of the image after embedding is destroyed it would not be able to reconstruct itself if that destroyed piece's reference content was destroyed with it.

\hspace{0pt} \\
An attempt was initially made to embed the image reference content blocks randomly into the original image.
This process however produced a much lower tamper rate due to the fact that the image reference content was often embedded very close to the original image content that it was referencing.
The result was a lowered tamper rate.
The proposed method thus rather used the more successful method describe above.

\paragraph{Conjugation}
If an image reference content block is found to not be complex enough that block needs to be conjugated before embedding.
This is important because if a block is not complex enough it cannot be detected when extracting and it may cause visual distortions to the image since it is replacing a complex block in the original image.

\hspace{0pt} \\
The block complexity is calculated by using a border complexity method. \cite{beaullieubpcs}
That is for each binary bit that has an adjacent binary bit that is different than itself the border count is increased. 
The final border count is then divided with the theoretical maximum border count, which would be the border count for a grid of the same size with a checkerboard pattern.

\hspace{0pt} \\
To conjugate a block each value in the grid needs to be changed to the XOR value of the original grid value and the corresponding value in a checkerboard grid (starting with a 1 in the top left hand corner).
To reverse the conjugation this process simply needs to be repeated.

\hspace{0pt} \\
This method of conjugation is a simple method that makes a block more complex while still allowing the original values of the block to be retrieved.

\subsubsection{Fragile Watermark}
\label{impFragileWatermark}
In order to be able to detect which parts of the image have been tampered with a fragile watermark can be used.

\hspace{0pt} \\
An initial attempt was made to apply the method proposed in \cite{tian2002wavelet}.
This method is a reversible fragile watermark which means that the watermark can be removed, during the extraction and reconstruction process, to restore the original content bit by bit to what it was before watermarking, if the image was found to be authentic.

\hspace{0pt} \\
The method needed to be adapted to authenticate the image on a block level, because the image is divided into 8x8 blocks.
The method requires compression of bit streams in order to embed the watermark and to be able to extract the watermark again.
These bit streams are used to store the embedding locations of watermark.
The bit streams are rather small in the proposed method because they are only applicable to a specific 8x8 pixel block. 
This is because each block is treated as a separate embedding entity.
This results in the fact that there is not always enough redundancy to be able to compress the bit streams for embedding.

\hspace{0pt} \\
Another problem with this method was the large amount of noise that this method of watermarking introduces into the cover image since it also uses difference expansion as mentioned in \cite{tian2002reversible}.

\hspace{0pt} \\
The fragile watermark used in the proposed method embeds a calculated hash into the image that is used to authenticate the content when the image is reconstructed on the receiving end.

\hspace{0pt} \\
For each of the 8x8 pixel section in the image after embedding a hash is calculated by combining the binary of each of the 7 Most significant bit planes of that section. This binary hash stream is then used as the input to the SHA-256 hash function.
The output is a 256 bit hash string for that image section.
This hash string is then truncated to a length of 57 bits.
This is done to enable the conjugation map as well as the embedding map that was generated when embedding the image content (\ref{bpcsSteg}) to be stored at the end of the stream.

\hspace{0pt} \\
The SHA-256 hash used is truncated to a 57 bit hash. 
This means that the hash has y possible unique values 
\[ y = 57^2 = 3249 \]
The image has 512x512 pixels that are divided into 8x8 sections.
This means that there are k amount of unique sections in the image
\[x = \frac{512}{8} = 64 \]
\[k = x^2 =64^2 = 4096 \]
Since k \textgreater y the proposed method is subject to the pigeonhole principle \cite{cook1976short}.
The pigeonhole principle states that since the input for the hash function (k) is greater than the amount of unique outputs of the hash function (y) there will be duplicate hash values produced.
However since the generated hash values are calculated from the 7 MSB planes of each section and then compared to the bits stored in the LSB plane of that section it is highly unlikely, but not impossible, that a false positive for tampering will occur.
Extensive testing was conducted on a number of images and no situation was found where such a collision occurred within normal operation.
However should this case arise, the proposed method would simply restore that section as well.
Thus not having a major impact on the final result of the reconstruction.

\hspace{0pt} \\
The conjugation map is appended to the truncated hash string to create a binary string of 192 bits.
These 192 bits are finally embedded into the LSB plane of that specific section of the image after embedding effectively replacing all the bits in that bit plane with the generated bit stream.

\subsection{Extraction and Reconstruction}
\label{extractRestore}
\subsubsection{Image authentication}
The first step for the image extraction and reconstruction process is to determine which, if any, parts of the image after embedding has been tampered with.
This is accomplished by first completing steps 1-4 of the BPCS steg algorithm (\ref{bpcsSteg}).
for each section (section refers here to 8x8 pixel section, thus a section here contains all 8 bit planes) the authentication hash string is calculated as described in \ref{impFragileWatermark}. 
The embedded hash is then extracted from the LSB plane of that block.
The extracted hash is then compared with the calculated hash and if they match the section is authentic.
If they do not match then that section has been tampered with.

\subsubsection{Image reconstruction}
\hspace{0pt} \\
For each authentic block the 7 MSB planes have their complexity calculated.
If a bit plane block is found to be complex enough it is assumed that there is image information embedded into it.
The embedded conjugation map is extracted at this point and if it is found that any of the complex enough bit plane blocks were conjugated the conjugation algorithm is applied again to reverse the conjugation.

\hspace{0pt} \\
The embedded image content is extracted at this point from the processed bit plane blocks and the embedded image is reconstructed.
In order to know the location of the extracted pixels the embedding map that was embedded into the LSB bit plane of that image section is consulted \ref{bpcsSteg}.
The reconstructed image is then scaled up back to it's original size of 512x512 pixels.
The reconstructed image is then also split into bit plane blocks.
This is accomplished by first completing steps 1-4 of the BPCS steg algorithm (\ref{bpcsSteg}).
The bit plane blocks generated from the image after embedding now get iterated and each block that was found not to be authentic is replaced by the corresponding reconstructed bit plane block. 

\hspace{0pt} \\
This process restores the tampered areas of the image if their matching bit plane blocks could be extracted from the image. That is if the embedded blocks were not destroyed in the image modification. 
Obviously if too large a part of the image has been modified it would not be possible to accurately reconstruct the image because too much of the embedded image content would be lost.

\subsection{Conclusion}
//TODO 


\section{Results} 
\subsection{Introduction}
//TODO

In testing the proposed method a simple experiment was set up in which the original image was processed using the embedding process described in \ref{embedding}.
The results of that process can be seen in figure \ref{fig:lenaEmbedOnceEmbedding}, showing the original image and the image after the embedding process.
Note that in this case the Image Reference content was only embedded once

\begin{figure}[h]
\centerline{%
\includegraphics[scale=0.45]{"lena"}%
\hspace{0.1cm}
\includegraphics[scale=0.45]{"Lena Embed once 0.7 threshold/finalImage"}%
}%
\caption{Embedding Once. Left: Original Image, Right: Image After embedding}
\label{fig:lenaEmbedOnceEmbedding}
\end{figure}

\hspace{0pt} \\
All images will be evaluated using Peak Signal to Noise Ratio (PSNR) because it is the most widely used measurement for objective image quality and is easily comparable with previous research. \cite{wang2002image}
After the image after embedding was generated the PSNR of the image after embedding in relation to the original image was calculated.
In this instance the PSNR after embedding was: 34.92dB 

\hspace{0pt} \\
The next step in the experiment conducted was to modify the image after embedding (shown in figure \ref{fig:lenaEmbedOnceEmbedding}).
After the image was modified it was reconstructed using the method described in \ref{extractRestore}.
The results of this reconstruction can be seen in figure \ref{fig:lenaEmbedOnceRestoration}, showing the image after tampering and the image after reconstruction.

\begin{figure}[h]
\centerline{%
\includegraphics[scale=0.45]{"Lena Embed once 0.7 threshold/finalImage - Copy"}%
\hspace{0.1cm}
\includegraphics[scale=0.45]{"Lena Embed once 0.7 threshold/finalImageAfterRestoration"}%
}%
\caption{Embedding Once. Left: Image After Tampering, Right: Image After Restoration}
\label{fig:lenaEmbedOnceRestoration}
\end{figure}

\hspace{0pt} \\
After the image (shown in figure \ref{fig:lenaEmbedOnceRestoration}) was reconstructed the PSNR of the image after reconstruction (figure \ref{fig:lenaEmbedOnceRestoration}) was calculated in relation to the Original Image (shown in figure \ref{fig:lenaEmbedOnceEmbedding}).
In this instance the PSNR after restoration was: 34.89dB.

\hspace{0pt} \\
It was found in the experimentation process that if the image reference content is only embedded once into the original image that the quality of the Image after embedding as well as the quality of the image after reconstruction was relatively high.
It was however found that the tamper rate possible was quite low at \textless 3\%.
To attempt to remedy this problem another instance of the experiment was run with the only independent variable being the fact that the Image reference content was now being embedded twice.
The results can be seen in figure \ref{fig:lenaEmbedTwiceEmbedding} and figure \ref{fig:lenaEmbedTwiceRestoration}

\begin{figure}[h]
\centerline{%
\includegraphics[scale=0.45]{"lena"}%
\hspace{0.1cm}
\includegraphics[scale=0.45]{"Lena Embed twice 0.7 threshold/finalImage"}%
}%
\caption{Embedding Twice. Left: Original Image, Right: Image After embedding}
\label{fig:lenaEmbedTwiceEmbedding}
\end{figure}

\begin{figure}[h]
\centerline{%
\includegraphics[scale=0.45]{"Lena Embed twice 0.7 threshold/finalImage - Copy"}%
\hspace{0.1cm}
\includegraphics[scale=0.45]{"Lena Embed twice 0.7 threshold/finalImageAfterRestoration"}%
}%
\caption{Embedding Twice. Left: Image After Tampering, Right: Image After Restoration}
\label{fig:lenaEmbedTwiceRestoration}
\end{figure}

\hspace{0pt} \\
In order to embed the image reference content twice the image reference content needs to be half the size that is used when embedding once.
This reduces the quality of the image after reconstruction from the previous 34.89dB to 32.52 dB.
The tamper rate however is now increased from \textless 3\% to \textless 35\%

\hspace{0pt} \\
This experiment was also completed on the following image.
First Embedding the Image reference content once (figure \ref{fig:treeEmbedOnceEmbedding} and figure \ref{fig:treeEmbedOnceRestoration}):

\begin{figure}[h]
\centerline{%
\includegraphics[scale=0.3375]{"tree"}%
\hspace{0.1cm}
\includegraphics[scale=0.45]{"Tree Embed once 0.8 threshold/finalImage"}%
}%
\caption{Embedding Once. Left: Original Image, Right: Image After embedding}
\label{fig:treeEmbedOnceEmbedding}
\end{figure}

\hspace{0pt} \\
The PSNR of the image after embedding (show in figure \ref{fig:treeEmbedOnceEmbedding}) was 27.94dB.

\begin{figure}[h]
\centerline{%
\includegraphics[scale=0.45]{"Tree Embed once 0.8 threshold/finalImage - Copy"}%
\hspace{0.1cm}
\includegraphics[scale=0.45]{"Tree Embed once 0.8 threshold/finalImageAfterRestoration"}%
}%
\caption{Embedding Once. Left: Image After Tampering, Right: Image After Restoration}
\label{fig:treeEmbedOnceRestoration}
\end{figure}

\hspace{0pt} \\
The PSNR of the image after reconstruction (show in figure \ref{fig:treeEmbedOnceRestoration}) was 27.72dB.
The tamper rate, as was the case with the first image (figure \ref{fig:lenaEmbedOnceRestoration}), was also \textless 3\%.
The experiment was also conducted by embedding the Image reference content twice (figure \ref{fig:treeEmbedTwiceEmbedding} and figure \ref{fig:treeEmbedTwiceRestoration}).

\begin{figure}[h]
\centerline{%
\includegraphics[scale=0.3375]{"tree"}%
\hspace{0.1cm}
\includegraphics[scale=0.45]{"Tree Embed twice 0.8 threshold/finalImage"}%
}%
\caption{Embedding Twice. Left: Original Image, Right: Image After embedding}
\label{fig:treeEmbedTwiceEmbedding}
\end{figure}

\hspace{0pt} \\
The PSNR of the image after embedding (show in figure \ref{fig:treeEmbedTwiceEmbedding}) was 27.93dB.

\begin{figure}[h]
\centerline{%
\includegraphics[scale=0.45]{"Tree Embed twice 0.8 threshold/finalImage - Copy"}%
\hspace{0.1cm}
\includegraphics[scale=0.45]{"Tree Embed twice 0.8 threshold/finalImageAfterRestoration"}%
}%
\caption{Embedding Twice. Left: Image After Tampering, Right: Image After Restoration}
\label{fig:treeEmbedTwiceRestoration}
\end{figure}

\hspace{0pt} \\
The PSNR of the image after reconstruction (show in figure \ref{fig:treeEmbedOnceRestoration}) was 26.05dB.
The tamper rate, as was the case with the first image image (figure \ref{fig:lenaEmbedTwiceRestoration}), was increased from \textless 3\% to \textless 35\% with a similar reduction in quality experienced.

\hspace{0pt} \\
The second image used thus behaved in a similar manner to the first image with the only significant difference being the much lower PSNR values produced.

As an experimental control the results from the experiment in the proposed method will be compared to other current methods for images with self recovering capabilities.
This is discussed further in  section \ref{interpretation}.
\subsection{Conclusion}
//TODO 


\section{Interpretation of results}
\subsection{Introduction}
//TODO

\label{interpretation}
The proposed method for self-recovering images using the BPCS Steg embedding algorithm described in the preceding sections was shown to be effective.
According to Appendix B in \cite{korus2013efficient} the proposed method achieved Average to High quality reconstruction in the case of figure \ref{fig:lenaEmbedTwiceRestoration} and figure \ref{fig:lenaEmbedOnceRestoration} respectively.
The proposed method achieved Low quality reconstruction in the case of figure \ref{fig:treeEmbedOnceRestoration} and figure \ref{fig:treeEmbedTwiceRestoration} according to \cite{korus2013efficient}.

\hspace{0pt} \\
The quality measures mentioned were measured using the PSNR method. \cite{huynh2008scope} However determined that the validity of PSNR is limited to modifications within the same image.
It is thus not reliable to compare PSNR values between two different images.
With that in mind the image from figures \ref{fig:lenaEmbedOnceEmbedding} - \ref{fig:lenaEmbedTwiceRestoration} was specifically chosen because it is well used in the literature and can serve to compare to proposed method to other methods available in the literature.
Such comparisons follow below. 

\hspace{0pt} \\
The proposed method does not perform as well as the method described in \ref{ErasureChannelOverview}.
The proposed method achieves PSNR values that are about 5dB worse than the method described in \ref{ErasureChannelOverview}.
Compared to the method described in \ref{differenceExpansionOverview} the proposed method performs in a similar manner.
The PSNR values achieved are worse than that of the method in \ref{differenceExpansionOverview} but the difference is around 1-2dB and is thus almost not noticeable to the human eye.
It should also be mentioned that the proposed method uses no compression on the image reference content, similar to the method in \ref{differenceExpansionOverview}.
This method thus serves as a more equal comparison. 

\hspace{0pt} \\
\cite{wang2002image} Points out several shortcomings of methods of measuring and comparing image quality using methods such as PSNR. 
PSNR is a useful measure for objective image quality assessment to a certain degree however there are other important factors to consider. 
The one important factor is how a person would perceive the image quality.
Another important factor is if the meaning of the image is still clear even after reconstruction.
This would typically mean being able to identify key features of the image easily. 
The proposed method performs well under this form a visual analysis.

\hspace{0pt} \\
It was found during experimentation that image quality can vary greatly among different image using the proposed method.
This can be attributed to the fact that an adaptive embedding method is used and where the image reference content is embedded thus differs depending on the chosen original image.

\hspace{0pt} \\
The embedding rate and effects of the embedding rate seemed consistent across the different images used.
The embedding rate was low where the image reference content was only embedded once into the original image and compared poorly to methods such as the one described in \ref{DynamicBlockOverview}.
However it was found that if the image reference content is embedded twice into the original image that the tamper rate compares equally to that of methods such as the one described in \ref{DynamicBlockOverview}.

\subsection{Conclusion}
//TODO 

\section{Conclusion}
\subsection{Introduction}
//TODO 

The proposed method described used an adaptive embedding algorithm described in \ref{bpcsSteg}.
The proposed method was shown to provide good quality as well as a good tamper rate.
It was also shown that the quality of the image after embedding the image reference content and the image quality after reconstruction differs depending on the cover image chosen.
This was attributed to the adaptive embedding algorithm used.
It was also mentioned that no compression was used on the image reference content that was embedded into the original image.
If compression is used it may result in higher quality of the image after reconstruction as well as the image after embedding due to fewer modifications that will be made during embedding.

\subsection{Future work}
//TODO 

\bibliography{main}
\bibliographystyle{plain}

\end{document}
